{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Detection using OSCD \n",
    "\n",
    "This notebook demonstrates training a change detection model using the OSCD dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup \n",
    "\n",
    "Refer to README.md for environment setup. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import and Init Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# If using LightningAI, change the current working directory to the directory containing this notebook. \n",
    "REPO_DIR = \"/teamspace/studios/this_studio/eda-bids-hackathon-prep/\"  # Adjust as appropriate\n",
    "if os.path.exists(REPO_DIR):\n",
    "    os.chdir(os.path.join(REPO_DIR, \"sentinel2-modelling\"))\n",
    "\n",
    "# If you encounter a warning regarding gdal mising GDAL_DATA, run the following \n",
    "if os.environ.get('CONDA_PREFIX') is not None: \n",
    "    if os.environ.get('GDAL_DATA') is None: os.environ[\"CONDA_PREFIX\"] + r\"\\Library\\share\\gdal\"\n",
    "    if os.environ.get('PROJ_LIB') is None: os.environ[\"CONDA_PREFIX\"] + r\"\\Library\\share\\proj\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from typing import Dict, Optional\n",
    "from glob import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from PIL import Image\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchmetrics as tm\n",
    "from torchmetrics import Metric\n",
    "from torchmetrics.classification import BinaryJaccardIndex, BinaryF1Score\n",
    "\n",
    "from torchgeo.datasets import OSCD\n",
    "from torchgeo.datamodules import OSCDDataModule\n",
    "from torchgeo.trainers import SemanticSegmentationTask\n",
    "from torchgeo.datasets.utils import unbind_samples\n",
    "\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from lightning.pytorch import Trainer, seed_everything\n",
    "from lightning.pytorch.loggers import WandbLogger, TensorBoardLogger\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "from torchvision.transforms import Compose\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "import lightning\n",
    "print(lightning.__version__)\n",
    "\n",
    "seed_everything(543)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "# Load EDS credentials from .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if device == \"cuda\":\n",
    "    batch_size = 8\n",
    "    num_workers = 8\n",
    "elif device ==  \"cpu\":\n",
    "    batch_size = 4\n",
    "    num_workers = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Download\n",
    "This is a large dataset to download - download on CPU before switching to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(OSCD.all_bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(OSCD.rgb_bands)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the bands to experiment with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BANDS = ('B04', 'B03', 'B02', 'B8A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule = OSCDDataModule(\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    download=True,\n",
    "    bands=BANDS,\n",
    "    patch_size=256\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viz a sample, remembering they are patchified on training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.setup(stage=\"fit\")\n",
    "fig = datamodule.train_dataset.dataset.plot(datamodule.train_dataset[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "We will use a custom semantic segmentation model for change detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSemanticSegmentationTask(SemanticSegmentationTask):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.train_f1 = BinaryF1Score()\n",
    "        self.val_f1 = BinaryF1Score()\n",
    "        self.test_f1 = BinaryF1Score()\n",
    "        self.train_iou = BinaryJaccardIndex()\n",
    "        self.val_iou = BinaryJaccardIndex()\n",
    "        self.test_iou = BinaryJaccardIndex()\n",
    "\n",
    "    def plot(self, sample):\n",
    "        image1 = sample[\"image1\"]\n",
    "        image2 = sample[\"image2\"]\n",
    "        mask = sample[\"mask\"]\n",
    "        prediction = sample[\"prediction\"]\n",
    "\n",
    "        fig, axs = plt.subplots(nrows=1, ncols=4, figsize=(4 * 5, 5))\n",
    "        axs[0].imshow(image1.permute(1, 2, 0))\n",
    "        axs[0].axis(\"off\")\n",
    "        axs[1].imshow(image2.permute(1, 2, 0))\n",
    "        axs[1].axis(\"off\")\n",
    "        axs[2].imshow(mask)\n",
    "        axs[2].axis(\"off\")\n",
    "        axs[3].imshow(prediction)\n",
    "        axs[3].axis(\"off\")\n",
    "\n",
    "        axs[0].set_title(\"Image 1\")\n",
    "        axs[1].set_title(\"Image 2\")\n",
    "        axs[2].set_title(\"Mask\")\n",
    "        axs[3].set_title(\"Prediction\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        return fig\n",
    "\n",
    "    def training_step(self, *args, **kwargs):\n",
    "        batch = args[0]\n",
    "        batch_idx = args[1]\n",
    "        \n",
    "        image1 = batch[\"image1\"].float()\n",
    "        image2 = batch[\"image2\"].float()\n",
    "        x = torch.cat([image1, image2], dim=1)\n",
    "        y = batch[\"mask\"].long()\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=False)\n",
    "        self.train_metrics(y_hat, y)\n",
    "\n",
    "        y_hat_hard = y_hat.argmax(dim=1) # convert to hard predictions, i.e. 0 or 1\n",
    "        self.train_f1.update(y_hat_hard, y)\n",
    "        self.train_iou.update(y_hat_hard, y)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, *args, **kwargs):\n",
    "        batch = args[0]\n",
    "        batch_idx = args[1]\n",
    "        image1 = batch[\"image1\"]\n",
    "        image2 = batch[\"image2\"]\n",
    "        x = torch.cat([image1, image2], dim=1)\n",
    "        y = batch[\"mask\"]\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True)\n",
    "        self.val_metrics(y_hat, y)\n",
    "\n",
    "        y_hat_hard = y_hat.argmax(dim=1)\n",
    "        self.val_f1.update(y_hat_hard, y)\n",
    "        self.val_iou.update(y_hat_hard, y)\n",
    "        return loss\n",
    "\n",
    "    def test_step(self, *args, **kwargs):\n",
    "        batch = args[0]\n",
    "        batch_idx = args[1]\n",
    "        image1 = batch[\"image1\"]\n",
    "        image2 = batch[\"image2\"]\n",
    "        x = torch.cat([image1, image2], dim=1)\n",
    "        y = batch[\"mask\"]\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"test_loss\", loss, on_step=False, on_epoch=True)\n",
    "        self.test_metrics(y_hat, y)\n",
    "\n",
    "        y_hat_hard = y_hat.argmax(dim=1)\n",
    "        self.test_f1.update(y_hat_hard, y)\n",
    "        self.test_iou.update(y_hat_hard, y)\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        self.log(\"train_f1\", self.train_f1.compute())\n",
    "        self.train_f1.reset()\n",
    "        self.log(\"train_iou\", self.train_iou.compute())\n",
    "        self.train_iou.reset()\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        self.log(\"val_f1\", self.val_f1.compute())\n",
    "        self.val_f1.reset()\n",
    "        self.log(\"val_iou\", self.val_iou.compute())\n",
    "        self.val_iou.reset()\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        self.log(\"test_f1\", self.test_f1.compute())\n",
    "        self.log(\"test_iou\", self.test_iou.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = CustomSemanticSegmentationTask(\n",
    "    model=\"unet\",\n",
    "    weights=True,\n",
    "    num_classes=2,\n",
    "    in_channels=len(BANDS)*2,\n",
    "    loss=\"ce\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_logger = WandbLogger(\n",
    "    project=\"oscd\",  \n",
    "    log_model=True, # or 'all' \n",
    "    save_dir = \"wandb_logs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    logger=[wandb_logger],\n",
    "    min_epochs=20,\n",
    "    max_epochs=25,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model=task, datamodule=datamodule)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the test cell raises an error - ReferenceError: weakly-referenced object no longer exists\n",
    "\n",
    "Can you beat:\n",
    "```\n",
    "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
    "┃        Test metric        ┃       DataLoader 0        ┃\n",
    "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
    "│          test_f1          │    0.33471593260765076    │\n",
    "│         test_iou          │    0.2009963095188141     │\n",
    "│         test_loss         │    0.14401671290397644    │\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model=task, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log experiement to WandB\n",
    "wandb_logger.experiment.finish()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
